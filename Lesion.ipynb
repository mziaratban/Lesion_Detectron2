{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Detectron2_Lesion_2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"QHnVupBBn9eR","colab_type":"text"},"source":["\n","<img src=\"https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png\" width=\"500\">\n","\n"]},{"cell_type":"code","metadata":{"id":"u2kaGgOkX-lM","colab_type":"code","colab":{}},"source":["from google.colab import drive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2x1RGZNLYAIm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":129},"executionInfo":{"status":"ok","timestamp":1589523681114,"user_tz":-270,"elapsed":91299,"user":{"displayName":"Majid Ziaratban","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJsf6bpQxKwtWa0SyUoXSNtRyldtiRi8546de=s64","userId":"01174008996645122703"}},"outputId":"e0b4f83d-6e0f-400a-c995-f3e7e79887b9"},"source":["drive.mount(\"/content/gdrive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"321aO8lqYO_C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1589523713123,"user_tz":-270,"elapsed":997,"user":{"displayName":"Majid Ziaratban","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJsf6bpQxKwtWa0SyUoXSNtRyldtiRi8546de=s64","userId":"01174008996645122703"}},"outputId":"5e3f476b-afc3-4796-cb1e-fec88cfd043a"},"source":["%cd gdrive/My Drive/Colab Notebooks"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V9ugnsmoaG6Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":274},"executionInfo":{"status":"ok","timestamp":1588268172249,"user_tz":-270,"elapsed":24268,"user":{"displayName":"Majid Ziaratban","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJsf6bpQxKwtWa0SyUoXSNtRyldtiRi8546de=s64","userId":"01174008996645122703"}},"outputId":"07364893-fa23-4d91-bd98-548ff0138079"},"source":["! git pull\n","! git pull\n","! ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fatal: not a git repository (or any parent up to mount point /content)\n","Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n","fatal: not a git repository (or any parent up to mount point /content)\n","Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n","'Copy of Detectron2 Tutorial.ipynb'   keras-YOLOv3-model-set-master\n","'Copy of ultralytics YOLOv3'\t     'Lesion Detectron2.ipynb'\n","'Copy of Untitled0.ipynb'\t      output\n","'Detectron2_Lesion(2)(1).ipynb'       output2\n"," Detectron2_Lesion_2.ipynb\t      qqwweee\n","'Detectron2_Lesion(2).ipynb'\t      Untitled\n","'Detectron2 Lesion.ipynb'\t      Untitled0.ipynb\n"," images\t\t\t\t      Untitled1.ipynb\n"," input.jpg\t\t\t      yolov3-model-set.ipynb\n"," keras-yolo3-master\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9_FzH13EjseR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1589523881919,"user_tz":-270,"elapsed":165394,"user":{"displayName":"Majid Ziaratban","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJsf6bpQxKwtWa0SyUoXSNtRyldtiRi8546de=s64","userId":"01174008996645122703"}},"outputId":"ca22a6ea-20c2-40a5-f93e-7881c09a4d52"},"source":["# install dependencies: (use cu100 because colab is on CUDA 10.0)\n","!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https://download.pytorch.org/whl/torch_stable.html \n","!pip install cython pyyaml==5.1\n","!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n","import torch, torchvision\n","torch.__version__\n","!gcc --version\n","# opencv is pre-installed on colab"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.4+cu100\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torch-1.4.0%2Bcu100-cp36-cp36m-linux_x86_64.whl (723.9MB)\n","\u001b[K     |████████████████████████████████| 723.9MB 24kB/s \n","\u001b[?25hCollecting torchvision==0.5+cu100\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torchvision-0.5.0%2Bcu100-cp36-cp36m-linux_x86_64.whl (4.0MB)\n","\u001b[K     |████████████████████████████████| 4.1MB 34.7MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5+cu100) (1.18.4)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5+cu100) (1.12.0)\n","Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5+cu100) (7.0.0)\n","Installing collected packages: torch, torchvision\n","  Found existing installation: torch 1.5.0+cu101\n","    Uninstalling torch-1.5.0+cu101:\n","      Successfully uninstalled torch-1.5.0+cu101\n","  Found existing installation: torchvision 0.6.0+cu101\n","    Uninstalling torchvision-0.6.0+cu101:\n","      Successfully uninstalled torchvision-0.6.0+cu101\n","Successfully installed torch-1.4.0+cu100 torchvision-0.5.0+cu100\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.17)\n","Collecting pyyaml==5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/2c/9417b5c774792634834e730932745bc09a7d36754ca00acf1ccd1ac2594d/PyYAML-5.1.tar.gz (274kB)\n","\u001b[K     |████████████████████████████████| 276kB 3.5MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyyaml\n","  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyyaml: filename=PyYAML-5.1-cp36-cp36m-linux_x86_64.whl size=44074 sha256=0a2cb21c28cc126ca147cfed612d71194c5240d157ea880c3798c37448e845fd\n","  Stored in directory: /root/.cache/pip/wheels/ad/56/bc/1522f864feb2a358ea6f1a92b4798d69ac783a28e80567a18b\n","Successfully built pyyaml\n","Installing collected packages: pyyaml\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed pyyaml-5.1\n","Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n","  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-4nk2u0wu\n","  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-4nk2u0wu\n","Requirement already satisfied, skipping upgrade: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (46.1.3)\n","Requirement already satisfied, skipping upgrade: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (0.29.17)\n","Requirement already satisfied, skipping upgrade: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (3.2.1)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.18.4)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.2.0)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.12.0)\n","Building wheels for collected packages: pycocotools\n","  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycocotools: filename=pycocotools-2.0-cp36-cp36m-linux_x86_64.whl size=275266 sha256=06cd1597d90328ff4b0e1c9968b3196bef339089f03d3bc4d301da07223fc1fa\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-r6muemxh/wheels/90/51/41/646daf401c3bc408ff10de34ec76587a9b3ebfac8d21ca5c3a\n","Successfully built pycocotools\n","Installing collected packages: pycocotools\n","  Found existing installation: pycocotools 2.0.0\n","    Uninstalling pycocotools-2.0.0:\n","      Successfully uninstalled pycocotools-2.0.0\n","Successfully installed pycocotools-2.0\n","gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","Copyright (C) 2017 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vM54r6jlKTII","colab_type":"text"},"source":["# Install detectron2"]},{"cell_type":"code","metadata":{"id":"b-i4hmGYk1dL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1589523891713,"user_tz":-270,"elapsed":171006,"user":{"displayName":"Majid Ziaratban","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJsf6bpQxKwtWa0SyUoXSNtRyldtiRi8546de=s64","userId":"01174008996645122703"}},"outputId":"a8c86e95-3fd3-4197-aa54-8870c83b099f"},"source":["# install detectron2:\n","!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html\n","Collecting detectron2\n","\u001b[?25l  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/detectron2-0.1.1%2Bcu100-cp36-cp36m-linux_x86_64.whl (6.2MB)\n","\u001b[K     |████████████████████████████████| 6.2MB 617kB/s \n","\u001b[?25hRequirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from detectron2) (7.0.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.8.7)\n","Collecting yacs>=0.1.6\n","  Downloading https://files.pythonhosted.org/packages/81/3b/40e876afde9f5ffa1cfdce10565aba85b0dc2e067ed551dfb566cfee6d4d/yacs-0.1.7-py3-none-any.whl\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.1.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2) (3.2.1)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2) (4.41.1)\n","Collecting fvcore\n","  Downloading https://files.pythonhosted.org/packages/43/3a/50bb1e1b1acbf5e9b79f9f0c078cd3e9694e453a61cd0f07cc8dd1e1872f/fvcore-0.1.1.post200513.tar.gz\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.16.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2) (2.2.1)\n","Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot->detectron2) (2.4.7)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2) (5.1)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.18.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.8.1)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (46.1.3)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.34.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.0.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.28.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.6.0.post3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.4.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.2.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.9.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.12.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (2.23.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.10.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.7.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2020.4.5.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (0.2.8)\n","Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (3.1.1)\n","Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2) (0.4.8)\n","Building wheels for collected packages: fvcore\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.1.post200513-cp36-none-any.whl size=40893 sha256=071a714dbdbd7e4e3163f5ded7182add79a8c7f33afa952b2cbc180bdbac1f93\n","  Stored in directory: /root/.cache/pip/wheels/a2/f6/77/551770c4b8cd75e9335cd0acf59c08d60a8684048b19da6702\n","Successfully built fvcore\n","Installing collected packages: yacs, portalocker, fvcore, detectron2\n","Successfully installed detectron2-0.1.1+cu100 fvcore-0.1.1.post200513 portalocker-1.7.0 yacs-0.1.7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZyAvNCJMmvFF","colab_type":"code","colab":{}},"source":["# You may need to restart your runtime prior to this, to let your installation take effect\n","# Some basic setup:\n","# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import cv2\n","import random\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vk4gID50K03a","colab_type":"text"},"source":["# Run a pre-trained detectron2 model"]},{"cell_type":"markdown","metadata":{"id":"JgKyUL4pngvE","colab_type":"text"},"source":["We first download a random image from the COCO dataset:"]},{"cell_type":"markdown","metadata":{"id":"b2bjrfb2LDeo","colab_type":"text"},"source":["# Train on a custom dataset"]},{"cell_type":"markdown","metadata":{"id":"tjbUIhSxUdm_","colab_type":"text"},"source":["In this section, we show how to train an existing detectron2 model on a custom dataset in a new format.\n","\n","We use [the balloon segmentation dataset](https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon)\n","which only has one class: balloon.\n","We'll train a balloon segmentation model from an existing model pre-trained on COCO dataset, available in detectron2's model zoo.\n","\n","Note that COCO dataset does not have the \"balloon\" category. We'll be able to recognize this new class in a few minutes.\n","\n","## Prepare the dataset"]},{"cell_type":"markdown","metadata":{"id":"tVJoOm6LVJwW","colab_type":"text"},"source":["Register the balloon dataset to detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).\n","Here, the dataset is in its custom format, therefore we write a function to parse it and prepare it into detectron2's standard format. See the tutorial for more details.\n"]},{"cell_type":"code","metadata":{"id":"PIbAM2pv-urF","colab_type":"code","colab":{}},"source":["# if your dataset is in COCO format, this cell can be replaced by the following three lines:\n","# from detectron2.data.datasets import register_coco_instances\n","# register_coco_instances(\"my_dataset_train\", {}, \"json_annotation_train.json\", \"path/to/image/dir\")\n","# register_coco_instances(\"my_dataset_val\", {}, \"json_annotation_val.json\", \"path/to/image/dir\")\n","\n","import os\n","import numpy as np\n","import json\n","from detectron2.structures import BoxMode\n","\n","def get_balloon_dicts(img_dir):\n","    json_file = os.path.join(img_dir, \"via_region_data.json\")\n","    with open(json_file) as f:\n","        imgs_anns = json.load(f)\n","\n","    dataset_dicts = []\n","    for idx, v in enumerate(imgs_anns.values()):\n","        record = {}\n","        print('index:  ',str(idx))\n","        \n","        filename = os.path.join(img_dir, v[\"filename\"])\n","        height, width = cv2.imread(filename).shape[:2]\n","        \n","        record[\"file_name\"] = filename\n","        record[\"image_id\"] = idx\n","        record[\"height\"] = height\n","        record[\"width\"] = width\n","      \n","        annos = v[\"regions\"]\n","        objs = []\n","        for _, anno in annos.items():\n","            assert not anno[\"region_attributes\"]\n","            anno = anno[\"shape_attributes\"]\n","            px = anno[\"all_points_x\"]\n","            py = anno[\"all_points_y\"]\n","            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n","            poly = [p for x in poly for p in x]\n","\n","            obj = {\n","                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n","                \"bbox_mode\": BoxMode.XYXY_ABS,\n","                \"segmentation\": [poly],\n","                \"category_id\": 0,\n","                \"iscrowd\": 0\n","            }\n","            objs.append(obj)\n","        record[\"annotations\"] = objs\n","        dataset_dicts.append(record)\n","    return dataset_dicts\n","\n","from detectron2.data import DatasetCatalog, MetadataCatalog\n","for d in [\"train\", \"val\",\"valid750\",\"test1\",\"test2\",\"test3\",\"test4\",\"Train_img_aug1_VLY\"]:\n","#for d in [\"test3\"]:\n","    DatasetCatalog.register(\"balloon_\" + d, lambda d=d: get_balloon_dicts(\"images/\" + d))\n","    MetadataCatalog.get(\"balloon_\" + d).set(thing_classes=[\"lesion\"])\n","balloon_metadata = MetadataCatalog.get(\"balloon_train\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ljbWTX0Wi8E","colab_type":"text"},"source":["To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set:\n","\n"]},{"cell_type":"code","metadata":{"id":"UkNbUzUOLYf0","colab_type":"code","colab":{}},"source":["#dataset_dicts = get_balloon_dicts(\"images/val\")\n","#for d in random.sample(dataset_dicts, 3):\n","#    img = cv2.imread(d[\"file_name\"])\n","#    visualizer = Visualizer(img[:, :, ::-1], metadata=balloon_metadata, scale=0.5)\n","#    vis = visualizer.draw_dataset_dict(d)\n","#    cv2_imshow(vis.get_image()[:, :, ::-1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wlqXIXXhW8dA","colab_type":"text"},"source":["## Train!\n","\n","Now, let's fine-tune a coco-pretrained R50-FPN Mask R-CNN model on the balloon dataset. It takes ~6 minutes to train 300 iterations on Colab's K80 GPU, or ~2 minutes on a P100 GPU.\n"]},{"cell_type":"code","metadata":{"id":"7unkuuiqLdqd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1589524812282,"user_tz":-270,"elapsed":7369,"user":{"displayName":"Majid Ziaratban","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJsf6bpQxKwtWa0SyUoXSNtRyldtiRi8546de=s64","userId":"01174008996645122703"}},"outputId":"075e86f1-6670-46f6-d887-e29db10f02a5"},"source":["from detectron2.engine import DefaultTrainer\n","from detectron2.config import get_cfg\n","\n","cfg = get_cfg()\n","#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n","#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_DC5_3x.yaml\"))\n","#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n","#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_C4_3x.yaml\"))\n","#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n","#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_DC5_3x.yaml\"))\n","#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n","\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\"))\n","#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n","\n","#cfg.DATASETS.TRAIN = (\"balloon_train_img4retina\",)\n","#cfg.DATASETS.TRAIN = (\"balloon_train_img4mask\",)\n","#cfg.DATASETS.TRAIN = (\"balloon_Train_img_aug1_VLY\",)\n","cfg.DATASETS.TRAIN = (\"balloon_val\",)\n","cfg.DATASETS.TEST = ()\n","cfg.DATALOADER.NUM_WORKERS = 2\n","#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n","#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\n","#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_DC5_3x.yaml\")  # Let training initialize from model zoo\n","#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_C4_3x.yaml\")  # Let training initialize from model zoo\n","#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\n","#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_DC5_3x.yaml\")  # Let training initialize from model zoo\n","#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\n","\n","#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\n","#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\n","\n","cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_5000_retinanet_R_101_FPN_3x_9460.pth\")\n","#cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_5000_mask_rcnn_X_101_32x8d_FPN_3x.pth\")\n","\n","#cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_retina_trainedBy_aug3yolo.pth\")\n","#cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_mask_trainedBy_aug4retina.pth\")\n","#cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_mask_trainedBy_aug4retina2.pth\")\n","#cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_mask_VLY.pth\")\n","\n","cfg.SOLVER.IMS_PER_BATCH = 2\n","cfg.SOLVER.BASE_LR = 0.0001  # pick a good LR\n","cfg.SOLVER.MAX_ITER = 5000    # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # faster, and good enough for this toy dataset (default: 512)\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon)\n","\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","trainer = DefaultTrainer(cfg) \n","trainer.resume_or_load(resume=False)\n","trainer.train()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading config /usr/local/lib/python3.6/dist-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[05/15 06:40:06 d2.engine.defaults]: \u001b[0mModel:\n","RetinaNet(\n","  (backbone): FPN(\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelP6P7(\n","      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    )\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (6): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (7): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (8): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (9): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (10): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (11): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (12): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (13): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (14): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (15): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (16): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (17): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (18): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (19): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (20): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (21): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (22): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (head): RetinaNetHead(\n","    (cls_subnet): Sequential(\n","      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU()\n","      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU()\n","      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU()\n","      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (7): ReLU()\n","    )\n","    (bbox_subnet): Sequential(\n","      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU()\n","      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU()\n","      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): ReLU()\n","      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (7): ReLU()\n","    )\n","    (cls_score): Conv2d(256, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  )\n","  (anchor_generator): DefaultAnchorGenerator(\n","    (cell_anchors): BufferList()\n","  )\n",")\n","index:   0\n","index:   1\n","index:   2\n","index:   3\n","index:   4\n","index:   5\n","index:   6\n","index:   7\n","index:   8\n","index:   9\n","index:   10\n","index:   11\n","index:   12\n","index:   13\n","index:   14\n","index:   15\n","index:   16\n","index:   17\n","index:   18\n","index:   19\n","index:   20\n","index:   21\n","index:   22\n","index:   23\n","index:   24\n","index:   25\n","index:   26\n","index:   27\n","index:   28\n","index:   29\n","index:   30\n","index:   31\n","index:   32\n","index:   33\n","index:   34\n","index:   35\n","index:   36\n","index:   37\n","index:   38\n","index:   39\n","index:   40\n","index:   41\n","index:   42\n","index:   43\n","index:   44\n","index:   45\n","index:   46\n","index:   47\n","index:   48\n","index:   49\n","index:   50\n","index:   51\n","index:   52\n","index:   53\n","index:   54\n","index:   55\n","index:   56\n","index:   57\n","index:   58\n","index:   59\n","index:   60\n","index:   61\n","index:   62\n","index:   63\n","index:   64\n","index:   65\n","index:   66\n","index:   67\n","index:   68\n","index:   69\n","index:   70\n","index:   71\n","index:   72\n","index:   73\n","index:   74\n","index:   75\n","index:   76\n","index:   77\n","index:   78\n","index:   79\n","index:   80\n","index:   81\n","index:   82\n","index:   83\n","index:   84\n","index:   85\n","index:   86\n","index:   87\n","index:   88\n","index:   89\n","index:   90\n","index:   91\n","index:   92\n","index:   93\n","index:   94\n","index:   95\n","index:   96\n","index:   97\n","index:   98\n","index:   99\n","index:   100\n","index:   101\n","index:   102\n","index:   103\n","index:   104\n","index:   105\n","index:   106\n","index:   107\n","index:   108\n","index:   109\n","index:   110\n","index:   111\n","index:   112\n","index:   113\n","index:   114\n","index:   115\n","index:   116\n","index:   117\n","index:   118\n","index:   119\n","index:   120\n","index:   121\n","index:   122\n","index:   123\n","index:   124\n","index:   125\n","index:   126\n","index:   127\n","index:   128\n","index:   129\n","index:   130\n","index:   131\n","index:   132\n","index:   133\n","index:   134\n","index:   135\n","index:   136\n","index:   137\n","index:   138\n","index:   139\n","index:   140\n","index:   141\n","index:   142\n","index:   143\n","index:   144\n","index:   145\n","index:   146\n","index:   147\n","index:   148\n","index:   149\n","\u001b[32m[05/15 06:40:08 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 150 images left.\n","\u001b[32m[05/15 06:40:08 d2.data.common]: \u001b[0mSerializing 150 elements to byte tensors and concatenating them all ...\n","\u001b[32m[05/15 06:40:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[32m[05/15 06:40:08 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[05/15 06:40:08 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[05/15 06:40:11 d2.engine.train_loop]: \u001b[0mStarting training from iteration 5000\n","\u001b[32m[05/15 06:40:11 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:00 (0:00:00 on hooks)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hBXeH8UXFcqU","colab_type":"code","colab":{}},"source":["# Look at training curves in tensorboard:\n","#%load_ext tensorboard\n","#%tensorboard --logdir output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0e4vdDIOXyxF","colab_type":"text"},"source":["## Inference & evaluation using the trained model\n","Now, let's run inference with the trained model on the balloon validation dataset. First, let's create a predictor using the model we just trained:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qWq1XHfDWiXO","colab_type":"text"},"source":["Then, we randomly select several samples to visualize the prediction results."]},{"cell_type":"code","metadata":{"id":"h9tECBQCvMv3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1589525371397,"user_tz":-270,"elapsed":471369,"user":{"displayName":"Majid Ziaratban","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSJsf6bpQxKwtWa0SyUoXSNtRyldtiRi8546de=s64","userId":"01174008996645122703"}},"outputId":"771fd0bf-ee01-48b1-a280-e900532d8a89"},"source":["#from detectron2.engine import DefaultTrainer\n","from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","from detectron2.data import build_detection_test_loader\n","#evaluator = COCOEvaluator(\"balloon_val\", cfg, False, output_dir=\"./output/\")\n","#val_loader = build_detection_test_loader(cfg, \"balloon_val\")\n","evaluator = COCOEvaluator(\"balloon_valid750\", cfg, False, output_dir=\"./output/\")\n","val_loader = build_detection_test_loader(cfg, \"balloon_valid750\")\n","\n","inference_on_dataset(trainer.model, val_loader, evaluator)\n","# another equivalent way is to use trainer.test"],"execution_count":null,"outputs":[{"output_type":"stream","text":["index:   0\n","index:   1\n","index:   2\n","index:   3\n","index:   4\n","index:   5\n","index:   6\n","index:   7\n","index:   8\n","index:   9\n","index:   10\n","index:   11\n","index:   12\n","index:   13\n","index:   14\n","index:   15\n","index:   16\n","index:   17\n","index:   18\n","index:   19\n","index:   20\n","index:   21\n","index:   22\n","index:   23\n","index:   24\n","index:   25\n","index:   26\n","index:   27\n","index:   28\n","index:   29\n","index:   30\n","index:   31\n","index:   32\n","index:   33\n","index:   34\n","index:   35\n","index:   36\n","index:   37\n","index:   38\n","index:   39\n","index:   40\n","index:   41\n","index:   42\n","index:   43\n","index:   44\n","index:   45\n","index:   46\n","index:   47\n","index:   48\n","index:   49\n","index:   50\n","index:   51\n","index:   52\n","index:   53\n","index:   54\n","index:   55\n","index:   56\n","index:   57\n","index:   58\n","index:   59\n","index:   60\n","index:   61\n","index:   62\n","index:   63\n","index:   64\n","index:   65\n","index:   66\n","index:   67\n","index:   68\n","index:   69\n","index:   70\n","index:   71\n","index:   72\n","index:   73\n","index:   74\n","index:   75\n","index:   76\n","index:   77\n","index:   78\n","index:   79\n","index:   80\n","index:   81\n","index:   82\n","index:   83\n","index:   84\n","index:   85\n","index:   86\n","index:   87\n","index:   88\n","index:   89\n","index:   90\n","index:   91\n","index:   92\n","index:   93\n","index:   94\n","index:   95\n","index:   96\n","index:   97\n","index:   98\n","index:   99\n","index:   100\n","index:   101\n","index:   102\n","index:   103\n","index:   104\n","index:   105\n","index:   106\n","index:   107\n","index:   108\n","index:   109\n","index:   110\n","index:   111\n","index:   112\n","index:   113\n","index:   114\n","index:   115\n","index:   116\n","index:   117\n","index:   118\n","index:   119\n","index:   120\n","index:   121\n","index:   122\n","index:   123\n","index:   124\n","index:   125\n","index:   126\n","index:   127\n","index:   128\n","index:   129\n","index:   130\n","index:   131\n","index:   132\n","index:   133\n","index:   134\n","index:   135\n","index:   136\n","index:   137\n","index:   138\n","index:   139\n","index:   140\n","index:   141\n","index:   142\n","index:   143\n","index:   144\n","index:   145\n","index:   146\n","index:   147\n","index:   148\n","index:   149\n","index:   150\n","index:   151\n","index:   152\n","index:   153\n","index:   154\n","index:   155\n","index:   156\n","index:   157\n","index:   158\n","index:   159\n","index:   160\n","index:   161\n","index:   162\n","index:   163\n","index:   164\n","index:   165\n","index:   166\n","index:   167\n","index:   168\n","index:   169\n","index:   170\n","index:   171\n","index:   172\n","index:   173\n","index:   174\n","index:   175\n","index:   176\n","index:   177\n","index:   178\n","index:   179\n","index:   180\n","index:   181\n","index:   182\n","index:   183\n","index:   184\n","index:   185\n","index:   186\n","index:   187\n","index:   188\n","index:   189\n","index:   190\n","index:   191\n","index:   192\n","index:   193\n","index:   194\n","index:   195\n","index:   196\n","index:   197\n","index:   198\n","index:   199\n","index:   200\n","index:   201\n","index:   202\n","index:   203\n","index:   204\n","index:   205\n","index:   206\n","index:   207\n","index:   208\n","index:   209\n","index:   210\n","index:   211\n","index:   212\n","index:   213\n","index:   214\n","index:   215\n","index:   216\n","index:   217\n","index:   218\n","index:   219\n","index:   220\n","index:   221\n","index:   222\n","index:   223\n","index:   224\n","index:   225\n","index:   226\n","index:   227\n","index:   228\n","index:   229\n","index:   230\n","index:   231\n","index:   232\n","index:   233\n","index:   234\n","index:   235\n","index:   236\n","index:   237\n","index:   238\n","index:   239\n","index:   240\n","index:   241\n","index:   242\n","index:   243\n","index:   244\n","index:   245\n","index:   246\n","index:   247\n","index:   248\n","index:   249\n","index:   250\n","index:   251\n","index:   252\n","index:   253\n","index:   254\n","index:   255\n","index:   256\n","index:   257\n","index:   258\n","index:   259\n","index:   260\n","index:   261\n","index:   262\n","index:   263\n","index:   264\n","index:   265\n","index:   266\n","index:   267\n","index:   268\n","index:   269\n","index:   270\n","index:   271\n","index:   272\n","index:   273\n","index:   274\n","index:   275\n","index:   276\n","index:   277\n","index:   278\n","index:   279\n","index:   280\n","index:   281\n","index:   282\n","index:   283\n","index:   284\n","index:   285\n","index:   286\n","index:   287\n","index:   288\n","index:   289\n","index:   290\n","index:   291\n","index:   292\n","index:   293\n","index:   294\n","index:   295\n","index:   296\n","index:   297\n","index:   298\n","index:   299\n","index:   300\n","index:   301\n","index:   302\n","index:   303\n","index:   304\n","index:   305\n","index:   306\n","index:   307\n","index:   308\n","index:   309\n","index:   310\n","index:   311\n","index:   312\n","index:   313\n","index:   314\n","index:   315\n","index:   316\n","index:   317\n","index:   318\n","index:   319\n","index:   320\n","index:   321\n","index:   322\n","index:   323\n","index:   324\n","index:   325\n","index:   326\n","index:   327\n","index:   328\n","index:   329\n","index:   330\n","index:   331\n","index:   332\n","index:   333\n","index:   334\n","index:   335\n","index:   336\n","index:   337\n","index:   338\n","index:   339\n","index:   340\n","index:   341\n","index:   342\n","index:   343\n","index:   344\n","index:   345\n","index:   346\n","index:   347\n","index:   348\n","index:   349\n","index:   350\n","index:   351\n","index:   352\n","index:   353\n","index:   354\n","index:   355\n","index:   356\n","index:   357\n","index:   358\n","index:   359\n","index:   360\n","index:   361\n","index:   362\n","index:   363\n","index:   364\n","index:   365\n","index:   366\n","index:   367\n","index:   368\n","index:   369\n","index:   370\n","index:   371\n","index:   372\n","index:   373\n","index:   374\n","index:   375\n","index:   376\n","index:   377\n","index:   378\n","index:   379\n","index:   380\n","index:   381\n","index:   382\n","index:   383\n","index:   384\n","index:   385\n","index:   386\n","index:   387\n","index:   388\n","index:   389\n","index:   390\n","index:   391\n","index:   392\n","index:   393\n","index:   394\n","index:   395\n","index:   396\n","index:   397\n","index:   398\n","index:   399\n","index:   400\n","index:   401\n","index:   402\n","index:   403\n","index:   404\n","index:   405\n","index:   406\n","index:   407\n","index:   408\n","index:   409\n","index:   410\n","index:   411\n","index:   412\n","index:   413\n","index:   414\n","index:   415\n","index:   416\n","index:   417\n","index:   418\n","index:   419\n","index:   420\n","index:   421\n","index:   422\n","index:   423\n","index:   424\n","index:   425\n","index:   426\n","index:   427\n","index:   428\n","index:   429\n","index:   430\n","index:   431\n","index:   432\n","index:   433\n","index:   434\n","index:   435\n","index:   436\n","index:   437\n","index:   438\n","index:   439\n","index:   440\n","index:   441\n","index:   442\n","index:   443\n","index:   444\n","index:   445\n","index:   446\n","index:   447\n","index:   448\n","index:   449\n","index:   450\n","index:   451\n","index:   452\n","index:   453\n","index:   454\n","index:   455\n","index:   456\n","index:   457\n","index:   458\n","index:   459\n","index:   460\n","index:   461\n","index:   462\n","index:   463\n","index:   464\n","index:   465\n","index:   466\n","index:   467\n","index:   468\n","index:   469\n","index:   470\n","index:   471\n","index:   472\n","index:   473\n","index:   474\n","index:   475\n","index:   476\n","index:   477\n","index:   478\n","index:   479\n","index:   480\n","index:   481\n","index:   482\n","index:   483\n","index:   484\n","index:   485\n","index:   486\n","index:   487\n","index:   488\n","index:   489\n","index:   490\n","index:   491\n","index:   492\n","index:   493\n","index:   494\n","index:   495\n","index:   496\n","index:   497\n","index:   498\n","index:   499\n","index:   500\n","index:   501\n","index:   502\n","index:   503\n","index:   504\n","index:   505\n","index:   506\n","index:   507\n","index:   508\n","index:   509\n","index:   510\n","index:   511\n","index:   512\n","index:   513\n","index:   514\n","index:   515\n","index:   516\n","index:   517\n","index:   518\n","index:   519\n","index:   520\n","index:   521\n","index:   522\n","index:   523\n","index:   524\n","index:   525\n","index:   526\n","index:   527\n","index:   528\n","index:   529\n","index:   530\n","index:   531\n","index:   532\n","index:   533\n","index:   534\n","index:   535\n","index:   536\n","index:   537\n","index:   538\n","index:   539\n","index:   540\n","index:   541\n","index:   542\n","index:   543\n","index:   544\n","index:   545\n","index:   546\n","index:   547\n","index:   548\n","index:   549\n","index:   550\n","index:   551\n","index:   552\n","index:   553\n","index:   554\n","index:   555\n","index:   556\n","index:   557\n","index:   558\n","index:   559\n","index:   560\n","index:   561\n","index:   562\n","index:   563\n","index:   564\n","index:   565\n","index:   566\n","index:   567\n","index:   568\n","index:   569\n","index:   570\n","index:   571\n","index:   572\n","index:   573\n","index:   574\n","index:   575\n","index:   576\n","index:   577\n","index:   578\n","index:   579\n","index:   580\n","index:   581\n","index:   582\n","index:   583\n","index:   584\n","index:   585\n","index:   586\n","index:   587\n","index:   588\n","index:   589\n","index:   590\n","index:   591\n","index:   592\n","index:   593\n","index:   594\n","index:   595\n","index:   596\n","index:   597\n","index:   598\n","index:   599\n","index:   600\n","index:   601\n","index:   602\n","index:   603\n","index:   604\n","index:   605\n","index:   606\n","index:   607\n","index:   608\n","index:   609\n","index:   610\n","index:   611\n","index:   612\n","index:   613\n","index:   614\n","index:   615\n","index:   616\n","index:   617\n","index:   618\n","index:   619\n","index:   620\n","index:   621\n","index:   622\n","index:   623\n","index:   624\n","index:   625\n","index:   626\n","index:   627\n","index:   628\n","index:   629\n","index:   630\n","index:   631\n","index:   632\n","index:   633\n","index:   634\n","index:   635\n","index:   636\n","index:   637\n","index:   638\n","index:   639\n","index:   640\n","index:   641\n","index:   642\n","index:   643\n","index:   644\n","index:   645\n","index:   646\n","index:   647\n","index:   648\n","index:   649\n","index:   650\n","index:   651\n","index:   652\n","index:   653\n","index:   654\n","index:   655\n","index:   656\n","index:   657\n","index:   658\n","index:   659\n","index:   660\n","index:   661\n","index:   662\n","index:   663\n","index:   664\n","index:   665\n","index:   666\n","index:   667\n","index:   668\n","index:   669\n","index:   670\n","index:   671\n","index:   672\n","index:   673\n","index:   674\n","index:   675\n","index:   676\n","index:   677\n","index:   678\n","index:   679\n","index:   680\n","index:   681\n","index:   682\n","index:   683\n","index:   684\n","index:   685\n","index:   686\n","index:   687\n","index:   688\n","index:   689\n","index:   690\n","index:   691\n","index:   692\n","index:   693\n","index:   694\n","index:   695\n","index:   696\n","index:   697\n","index:   698\n","index:   699\n","index:   700\n","index:   701\n","index:   702\n","index:   703\n","index:   704\n","index:   705\n","index:   706\n","index:   707\n","index:   708\n","index:   709\n","index:   710\n","index:   711\n","index:   712\n","index:   713\n","index:   714\n","index:   715\n","index:   716\n","index:   717\n","index:   718\n","index:   719\n","index:   720\n","index:   721\n","index:   722\n","index:   723\n","index:   724\n","index:   725\n","index:   726\n","index:   727\n","index:   728\n","index:   729\n","index:   730\n","index:   731\n","index:   732\n","index:   733\n","index:   734\n","index:   735\n","index:   736\n","index:   737\n","index:   738\n","index:   739\n","index:   740\n","index:   741\n","index:   742\n","index:   743\n","index:   744\n","index:   745\n","index:   746\n","index:   747\n","index:   748\n","index:   749\n","\u001b[32m[05/15 06:41:46 d2.data.common]: \u001b[0mSerializing 750 elements to byte tensors and concatenating them all ...\n","\u001b[32m[05/15 06:41:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.75 MiB\n","\u001b[32m[05/15 06:41:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 750 images\n","\u001b[32m[05/15 06:41:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/750. 0.6081 s / img. ETA=0:07:30\n","\u001b[32m[05/15 06:41:58 d2.evaluation.evaluator]: \u001b[0mInference done 20/750. 0.6088 s / img. ETA=0:07:25\n","\u001b[32m[05/15 06:42:04 d2.evaluation.evaluator]: \u001b[0mInference done 29/750. 0.6092 s / img. ETA=0:07:20\n","\u001b[32m[05/15 06:42:09 d2.evaluation.evaluator]: \u001b[0mInference done 38/750. 0.6095 s / img. ETA=0:07:15\n","\u001b[32m[05/15 06:42:15 d2.evaluation.evaluator]: \u001b[0mInference done 47/750. 0.6104 s / img. ETA=0:07:10\n","\u001b[32m[05/15 06:42:20 d2.evaluation.evaluator]: \u001b[0mInference done 56/750. 0.6109 s / img. ETA=0:07:05\n","\u001b[32m[05/15 06:42:26 d2.evaluation.evaluator]: \u001b[0mInference done 65/750. 0.6113 s / img. ETA=0:07:00\n","\u001b[32m[05/15 06:42:32 d2.evaluation.evaluator]: \u001b[0mInference done 74/750. 0.6119 s / img. ETA=0:06:55\n","\u001b[32m[05/15 06:42:37 d2.evaluation.evaluator]: \u001b[0mInference done 83/750. 0.6122 s / img. ETA=0:06:49\n","\u001b[32m[05/15 06:42:43 d2.evaluation.evaluator]: \u001b[0mInference done 92/750. 0.6124 s / img. ETA=0:06:44\n","\u001b[32m[05/15 06:42:48 d2.evaluation.evaluator]: \u001b[0mInference done 101/750. 0.6125 s / img. ETA=0:06:38\n","\u001b[32m[05/15 06:42:54 d2.evaluation.evaluator]: \u001b[0mInference done 110/750. 0.6126 s / img. ETA=0:06:33\n","\u001b[32m[05/15 06:42:59 d2.evaluation.evaluator]: \u001b[0mInference done 119/750. 0.6128 s / img. ETA=0:06:28\n","\u001b[32m[05/15 06:43:05 d2.evaluation.evaluator]: \u001b[0mInference done 128/750. 0.6128 s / img. ETA=0:06:22\n","\u001b[32m[05/15 06:43:10 d2.evaluation.evaluator]: \u001b[0mInference done 137/750. 0.6128 s / img. ETA=0:06:17\n","\u001b[32m[05/15 06:43:16 d2.evaluation.evaluator]: \u001b[0mInference done 146/750. 0.6128 s / img. ETA=0:06:11\n","\u001b[32m[05/15 06:43:21 d2.evaluation.evaluator]: \u001b[0mInference done 155/750. 0.6129 s / img. ETA=0:06:05\n","\u001b[32m[05/15 06:43:27 d2.evaluation.evaluator]: \u001b[0mInference done 164/750. 0.6129 s / img. ETA=0:06:00\n","\u001b[32m[05/15 06:43:33 d2.evaluation.evaluator]: \u001b[0mInference done 173/750. 0.6129 s / img. ETA=0:05:54\n","\u001b[32m[05/15 06:43:38 d2.evaluation.evaluator]: \u001b[0mInference done 182/750. 0.6129 s / img. ETA=0:05:49\n","\u001b[32m[05/15 06:43:44 d2.evaluation.evaluator]: \u001b[0mInference done 191/750. 0.6130 s / img. ETA=0:05:43\n","\u001b[32m[05/15 06:43:49 d2.evaluation.evaluator]: \u001b[0mInference done 200/750. 0.6130 s / img. ETA=0:05:38\n","\u001b[32m[05/15 06:43:55 d2.evaluation.evaluator]: \u001b[0mInference done 209/750. 0.6131 s / img. ETA=0:05:32\n","\u001b[32m[05/15 06:44:00 d2.evaluation.evaluator]: \u001b[0mInference done 218/750. 0.6132 s / img. ETA=0:05:27\n","\u001b[32m[05/15 06:44:06 d2.evaluation.evaluator]: \u001b[0mInference done 227/750. 0.6133 s / img. ETA=0:05:21\n","\u001b[32m[05/15 06:44:11 d2.evaluation.evaluator]: \u001b[0mInference done 236/750. 0.6135 s / img. ETA=0:05:16\n","\u001b[32m[05/15 06:44:17 d2.evaluation.evaluator]: \u001b[0mInference done 245/750. 0.6137 s / img. ETA=0:05:11\n","\u001b[32m[05/15 06:44:23 d2.evaluation.evaluator]: \u001b[0mInference done 254/750. 0.6138 s / img. ETA=0:05:05\n","\u001b[32m[05/15 06:44:28 d2.evaluation.evaluator]: \u001b[0mInference done 263/750. 0.6140 s / img. ETA=0:05:00\n","\u001b[32m[05/15 06:44:34 d2.evaluation.evaluator]: \u001b[0mInference done 272/750. 0.6142 s / img. ETA=0:04:54\n","\u001b[32m[05/15 06:44:39 d2.evaluation.evaluator]: \u001b[0mInference done 281/750. 0.6143 s / img. ETA=0:04:49\n","\u001b[32m[05/15 06:44:45 d2.evaluation.evaluator]: \u001b[0mInference done 290/750. 0.6145 s / img. ETA=0:04:43\n","\u001b[32m[05/15 06:44:51 d2.evaluation.evaluator]: \u001b[0mInference done 299/750. 0.6146 s / img. ETA=0:04:38\n","\u001b[32m[05/15 06:44:56 d2.evaluation.evaluator]: \u001b[0mInference done 308/750. 0.6146 s / img. ETA=0:04:32\n","\u001b[32m[05/15 06:45:02 d2.evaluation.evaluator]: \u001b[0mInference done 317/750. 0.6147 s / img. ETA=0:04:27\n","\u001b[32m[05/15 06:45:07 d2.evaluation.evaluator]: \u001b[0mInference done 326/750. 0.6149 s / img. ETA=0:04:21\n","\u001b[32m[05/15 06:45:13 d2.evaluation.evaluator]: \u001b[0mInference done 335/750. 0.6150 s / img. ETA=0:04:16\n","\u001b[32m[05/15 06:45:18 d2.evaluation.evaluator]: \u001b[0mInference done 344/750. 0.6152 s / img. ETA=0:04:10\n","\u001b[32m[05/15 06:45:24 d2.evaluation.evaluator]: \u001b[0mInference done 353/750. 0.6153 s / img. ETA=0:04:05\n","\u001b[32m[05/15 06:45:30 d2.evaluation.evaluator]: \u001b[0mInference done 362/750. 0.6153 s / img. ETA=0:03:59\n","\u001b[32m[05/15 06:45:35 d2.evaluation.evaluator]: \u001b[0mInference done 371/750. 0.6152 s / img. ETA=0:03:54\n","\u001b[32m[05/15 06:45:41 d2.evaluation.evaluator]: \u001b[0mInference done 380/750. 0.6152 s / img. ETA=0:03:48\n","\u001b[32m[05/15 06:45:46 d2.evaluation.evaluator]: \u001b[0mInference done 389/750. 0.6152 s / img. ETA=0:03:42\n","\u001b[32m[05/15 06:45:52 d2.evaluation.evaluator]: \u001b[0mInference done 398/750. 0.6151 s / img. ETA=0:03:37\n","\u001b[32m[05/15 06:45:57 d2.evaluation.evaluator]: \u001b[0mInference done 407/750. 0.6151 s / img. ETA=0:03:31\n","\u001b[32m[05/15 06:46:03 d2.evaluation.evaluator]: \u001b[0mInference done 416/750. 0.6151 s / img. ETA=0:03:26\n","\u001b[32m[05/15 06:46:08 d2.evaluation.evaluator]: \u001b[0mInference done 425/750. 0.6150 s / img. ETA=0:03:20\n","\u001b[32m[05/15 06:46:14 d2.evaluation.evaluator]: \u001b[0mInference done 434/750. 0.6150 s / img. ETA=0:03:15\n","\u001b[32m[05/15 06:46:20 d2.evaluation.evaluator]: \u001b[0mInference done 443/750. 0.6150 s / img. ETA=0:03:09\n","\u001b[32m[05/15 06:46:25 d2.evaluation.evaluator]: \u001b[0mInference done 452/750. 0.6150 s / img. ETA=0:03:03\n","\u001b[32m[05/15 06:46:31 d2.evaluation.evaluator]: \u001b[0mInference done 461/750. 0.6149 s / img. ETA=0:02:58\n","\u001b[32m[05/15 06:46:36 d2.evaluation.evaluator]: \u001b[0mInference done 470/750. 0.6149 s / img. ETA=0:02:52\n","\u001b[32m[05/15 06:46:42 d2.evaluation.evaluator]: \u001b[0mInference done 479/750. 0.6149 s / img. ETA=0:02:47\n","\u001b[32m[05/15 06:46:47 d2.evaluation.evaluator]: \u001b[0mInference done 488/750. 0.6149 s / img. ETA=0:02:41\n","\u001b[32m[05/15 06:46:53 d2.evaluation.evaluator]: \u001b[0mInference done 497/750. 0.6149 s / img. ETA=0:02:36\n","\u001b[32m[05/15 06:46:58 d2.evaluation.evaluator]: \u001b[0mInference done 506/750. 0.6148 s / img. ETA=0:02:30\n","\u001b[32m[05/15 06:47:04 d2.evaluation.evaluator]: \u001b[0mInference done 515/750. 0.6148 s / img. ETA=0:02:24\n","\u001b[32m[05/15 06:47:09 d2.evaluation.evaluator]: \u001b[0mInference done 524/750. 0.6147 s / img. ETA=0:02:19\n","\u001b[32m[05/15 06:47:15 d2.evaluation.evaluator]: \u001b[0mInference done 533/750. 0.6147 s / img. ETA=0:02:13\n","\u001b[32m[05/15 06:47:20 d2.evaluation.evaluator]: \u001b[0mInference done 542/750. 0.6147 s / img. ETA=0:02:08\n","\u001b[32m[05/15 06:47:26 d2.evaluation.evaluator]: \u001b[0mInference done 551/750. 0.6147 s / img. ETA=0:02:02\n","\u001b[32m[05/15 06:47:32 d2.evaluation.evaluator]: \u001b[0mInference done 560/750. 0.6147 s / img. ETA=0:01:57\n","\u001b[32m[05/15 06:47:37 d2.evaluation.evaluator]: \u001b[0mInference done 569/750. 0.6147 s / img. ETA=0:01:51\n","\u001b[32m[05/15 06:47:43 d2.evaluation.evaluator]: \u001b[0mInference done 578/750. 0.6148 s / img. ETA=0:01:46\n","\u001b[32m[05/15 06:47:48 d2.evaluation.evaluator]: \u001b[0mInference done 587/750. 0.6148 s / img. ETA=0:01:40\n","\u001b[32m[05/15 06:47:54 d2.evaluation.evaluator]: \u001b[0mInference done 596/750. 0.6148 s / img. ETA=0:01:35\n","\u001b[32m[05/15 06:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 605/750. 0.6149 s / img. ETA=0:01:29\n","\u001b[32m[05/15 06:48:05 d2.evaluation.evaluator]: \u001b[0mInference done 614/750. 0.6149 s / img. ETA=0:01:23\n","\u001b[32m[05/15 06:48:11 d2.evaluation.evaluator]: \u001b[0mInference done 623/750. 0.6150 s / img. ETA=0:01:18\n","\u001b[32m[05/15 06:48:16 d2.evaluation.evaluator]: \u001b[0mInference done 632/750. 0.6151 s / img. ETA=0:01:12\n","\u001b[32m[05/15 06:48:22 d2.evaluation.evaluator]: \u001b[0mInference done 641/750. 0.6152 s / img. ETA=0:01:07\n","\u001b[32m[05/15 06:48:27 d2.evaluation.evaluator]: \u001b[0mInference done 650/750. 0.6152 s / img. ETA=0:01:01\n","\u001b[32m[05/15 06:48:33 d2.evaluation.evaluator]: \u001b[0mInference done 659/750. 0.6152 s / img. ETA=0:00:56\n","\u001b[32m[05/15 06:48:39 d2.evaluation.evaluator]: \u001b[0mInference done 668/750. 0.6152 s / img. ETA=0:00:50\n","\u001b[32m[05/15 06:48:44 d2.evaluation.evaluator]: \u001b[0mInference done 677/750. 0.6152 s / img. ETA=0:00:45\n","\u001b[32m[05/15 06:48:50 d2.evaluation.evaluator]: \u001b[0mInference done 686/750. 0.6152 s / img. ETA=0:00:39\n","\u001b[32m[05/15 06:48:55 d2.evaluation.evaluator]: \u001b[0mInference done 695/750. 0.6152 s / img. ETA=0:00:33\n","\u001b[32m[05/15 06:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 704/750. 0.6152 s / img. ETA=0:00:28\n","\u001b[32m[05/15 06:49:06 d2.evaluation.evaluator]: \u001b[0mInference done 713/750. 0.6152 s / img. ETA=0:00:22\n","\u001b[32m[05/15 06:49:12 d2.evaluation.evaluator]: \u001b[0mInference done 722/750. 0.6152 s / img. ETA=0:00:17\n","\u001b[32m[05/15 06:49:18 d2.evaluation.evaluator]: \u001b[0mInference done 731/750. 0.6153 s / img. ETA=0:00:11\n","\u001b[32m[05/15 06:49:23 d2.evaluation.evaluator]: \u001b[0mInference done 740/750. 0.6153 s / img. ETA=0:00:06\n","\u001b[32m[05/15 06:49:29 d2.evaluation.evaluator]: \u001b[0mInference done 749/750. 0.6154 s / img. ETA=0:00:00\n","\u001b[32m[05/15 06:49:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:07:40.178585 (0.617689 s / img per device, on 1 devices)\n","\u001b[32m[05/15 06:49:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:07:38 (0.615378 s / img per device, on 1 devices)\n","\u001b[32m[05/15 06:49:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[05/15 06:49:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n","\u001b[32m[05/15 06:49:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n","Loading and preparing results...\n","DONE (t=0.01s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.60s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.653\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.957\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.717\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.622\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.670\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.729\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.730\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.682\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.744\n","\u001b[32m[05/15 06:49:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 65.284 | 95.736 | 71.690 |  nan  | 62.213 | 66.423 |\n","\u001b[32m[05/15 06:49:30 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('bbox',\n","              {'AP': 65.28441801018388,\n","               'AP50': 95.73623910492928,\n","               'AP75': 71.69047575580923,\n","               'APl': 66.42280300685562,\n","               'APm': 62.21311423088519,\n","               'APs': nan})])"]},"metadata":{"tags":[]},"execution_count":11}]}]}
